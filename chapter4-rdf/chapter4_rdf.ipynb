{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Forest Cover with Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.{functions=>F}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import org.apache.spark.sql.{functions => F}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_path = ../data/covtype/covtype.data\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../data/covtype/covtype.data"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data_path = \"../data/covtype/covtype.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataWithoutHeader = [_c0: int, _c1: int ... 53 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[_c0: int, _c1: int ... 53 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataWithoutHeader = spark.read.option(\"header\", \"false\").\n",
    "    option(\"inferSchema\", \"true\").csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "colNames = List(Elevation, Aspect, Slope, Horizontal_Distance_To_Hydrology, Vertical_Distance_To_Hydrology, Horizontal_Distance_To_Roadways, Hillshade_9am, Hillshade_Noon, Hillshade_3pm, Horizontal_Distance_To_Fire_Points, Wilderness_Area_0, Wilderness_Area_1, Wilderness_Area_2, Wilderness_Area_3, Soil_Type_0, Soil_Type_1, Soil_Type_2, Soil_Type_3, Soil_Type_4, Soil_Type_5, Soil_Type_6, Soil_Type_7, Soil_Type_8, Soil_Type_9, Soil_Type_10, Soil_Type_11, Soil_Type_12, Soil_Type_13, Soil_Type_14, Soil_Type_15, Soil_Type_16, Soil_Type_17, Soil_Type_18, Soil_Type_19, Soil_Type_20, Soil_Type_21, Soil_Type_22, Soil_Type_23, Soil_Type_24, Soil_Type_25, Soil_Type_26, Soil_Type_27, Soil_Type_28, Soil_Type_29, Soil_Type_30, Soil_Type_31, Soil_Type_32, Soil_Type_33, Soil_Type_34, Soil_...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "List(Elevation, Aspect, Slope, Horizontal_Distance_To_Hydrology, Vertical_Distance_To_Hydrology, Horizontal_Distance_To_Roadways, Hillshade_9am, Hillshade_Noon, Hillshade_3pm, Horizontal_Distance_To_Fire_Points, Wilderness_Area_0, Wilderness_Area_1, Wilderness_Area_2, Wilderness_Area_3, Soil_Type_0, Soil_Type_1, Soil_Type_2, Soil_Type_3, Soil_Type_4, Soil_Type_5, Soil_Type_6, Soil_Type_7, Soil_Type_8, Soil_Type_9, Soil_Type_10, Soil_Type_11, Soil_Type_12, Soil_Type_13, Soil_Type_14, Soil_Type_15, Soil_Type_16, Soil_Type_17, Soil_Type_18, Soil_Type_19, Soil_Type_20, Soil_Type_21, Soil_Type_22, Soil_Type_23, Soil_Type_24, Soil_Type_25, Soil_Type_26, Soil_Type_27, Soil_Type_28, Soil_Type_29, Soil_Type_30, Soil_Type_31, Soil_Type_32, Soil_Type_33, Soil_Type_34, Soil_Type_35, Soil_Type_36, Soil_Type_37, Soil_Type_38, Soil_Type_39, Cover_Type)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val colNames = Seq(\n",
    "        \"Elevation\", \"Aspect\", \"Slope\",\n",
    "        \"Horizontal_Distance_To_Hydrology\", \"Vertical_Distance_To_Hydrology\",\n",
    "        \"Horizontal_Distance_To_Roadways\",\n",
    "        \"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\",\n",
    "        \"Horizontal_Distance_To_Fire_Points\"\n",
    "      ) ++ (\n",
    "        (0 until 4).map(i => s\"Wilderness_Area_$i\")\n",
    "      ) ++ (\n",
    "        (0 until 40).map(i => s\"Soil_Type_$i\")\n",
    "      ) ++ Seq(\"Cover_Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data = [Elevation: int, Aspect: int ... 53 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Elevation: int, Aspect: int ... 53 more fields]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data = dataWithoutHeader.toDF(colNames:_*).withColumn(\"Cover_Type\", F.col(\"Cover_type\").cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2596,51,3,258,0,510,221,232,148,6279,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,5.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A First Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainData = [Elevation: int, Aspect: int ... 53 more fields]\n",
       "testData = [Elevation: int, Aspect: int ... 53 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Elevation: int, Aspect: int ... 53 more fields]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(trainData, testData) = data.randomSplit(Array(0.9, 0.1))\n",
    "trainData.cache()\n",
    "testData.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.feature.VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputCols = Array(Elevation, Aspect, Slope, Horizontal_Distance_To_Hydrology, Vertical_Distance_To_Hydrology, Horizontal_Distance_To_Roadways, Hillshade_9am, Hillshade_Noon, Hillshade_3pm, Horizontal_Distance_To_Fire_Points, Wilderness_Area_0, Wilderness_Area_1, Wilderness_Area_2, Wilderness_Area_3, Soil_Type_0, Soil_Type_1, Soil_Type_2, Soil_Type_3, Soil_Type_4, Soil_Type_5, Soil_Type_6, Soil_Type_7, Soil_Type_8, Soil_Type_9, Soil_Type_10, Soil_Type_11, Soil_Type_12, Soil_Type_13, Soil_Type_14, Soil_Type_15, Soil_Type_16, Soil_Type_17, Soil_Type_18, Soil_Type_19, Soil_Type_20, Soil_Type_21, Soil_Type_22, Soil_Type_23, Soil_Type_24, Soil_Type_25, Soil_Type_26, Soil_Type_27, Soil_Type_28, Soil_Type_29, Soil_Type_30, Soil_Type_31, Soil_Type_32, Soil_Type_33, Soil_Type_34, S...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Elevation, Aspect, Slope, Horizontal_Distance_To_Hydrology, Vertical_Distance_To_Hydrology, Horizontal_Distance_To_Roadways, Hillshade_9am, Hillshade_Noon, Hillshade_3pm, Horizontal_Distance_To_Fire_Points, Wilderness_Area_0, Wilderness_Area_1, Wilderness_Area_2, Wilderness_Area_3, Soil_Type_0, Soil_Type_1, Soil_Type_2, Soil_Type_3, Soil_Type_4, Soil_Type_5, Soil_Type_6, Soil_Type_7, Soil_Type_8, Soil_Type_9, Soil_Type_10, Soil_Type_11, Soil_Type_12, Soil_Type_13, Soil_Type_14, Soil_Type_15, Soil_Type_16, Soil_Type_17, Soil_Type_18, Soil_Type_19, Soil_Type_20, Soil_Type_21, Soil_Type_22, Soil_Type_23, Soil_Type_24, Soil_Type_25, Soil_Type_26, Soil_Type_27, Soil_Type_28, Soil_Type_29, Soil_Type_30, Soil_Type_31, Soil_Type_32, Soil_Type_33, Soil_Type_34, Soil_Type_35, Soil_Type_36, Soil_Type_37, Soil_Type_38, Soil_Type_39]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val inputCols = trainData.columns.filter(_ != \"Cover_Type\")\n",
    "val assembler = new VectorAssembler().setInputCols(inputCols)\n",
    "    .setOutputCol(\"featureVector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assembledTrainData = [Elevation: int, Aspect: int ... 54 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Elevation: int, Aspect: int ... 54 more fields]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val assembledTrainData = assembler.transform(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|featureVector                                                                                        |\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1863.0,37.0,17.0,120.0,18.0,90.0,217.0,202.0,115.0,769.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,5,6,7,8,9,13,18],[1874.0,18.0,14.0,90.0,208.0,209.0,135.0,793.0,1.0,1.0])                 |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1879.0,28.0,19.0,30.0,12.0,95.0,209.0,196.0,117.0,778.0,1.0,1.0])   |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1888.0,33.0,22.0,150.0,46.0,108.0,209.0,185.0,103.0,735.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1889.0,28.0,22.0,150.0,23.0,120.0,205.0,185.0,108.0,759.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1889.0,353.0,30.0,95.0,39.0,67.0,153.0,172.0,146.0,600.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1896.0,337.0,12.0,30.0,6.0,175.0,195.0,224.0,168.0,732.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1899.0,355.0,22.0,153.0,43.0,124.0,178.0,195.0,151.0,819.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1901.0,311.0,9.0,30.0,2.0,190.0,195.0,234.0,179.0,726.0,1.0,1.0])   |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1903.0,5.0,13.0,42.0,4.0,201.0,203.0,214.0,148.0,708.0,1.0,1.0])    |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,16],[1903.0,67.0,16.0,108.0,36.0,120.0,234.0,207.0,100.0,969.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1904.0,51.0,26.0,67.0,30.0,162.0,222.0,175.0,72.0,711.0,1.0,1.0])   |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1905.0,19.0,27.0,134.0,58.0,120.0,188.0,171.0,108.0,636.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1905.0,33.0,27.0,90.0,46.0,150.0,204.0,171.0,89.0,725.0,1.0,1.0])   |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,16],[1905.0,77.0,21.0,90.0,38.0,120.0,241.0,196.0,75.0,1025.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1906.0,356.0,20.0,150.0,55.0,120.0,184.0,201.0,151.0,726.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1916.0,24.0,25.0,212.0,74.0,175.0,197.0,177.0,105.0,789.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1916.0,320.0,24.0,190.0,60.0,162.0,151.0,210.0,195.0,832.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,23],[1918.0,321.0,28.0,42.0,17.0,85.0,139.0,201.0,196.0,402.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1919.0,44.0,26.0,162.0,68.0,150.0,216.0,173.0,77.0,706.0,1.0,1.0])  |\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembledTrainData.select(\"featureVector\").show(truncate = false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.classification.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifier = dtc_64312fa273bd\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dtc_64312fa273bd"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val classifier = new DecisionTreeClassifier().\n",
    "    setSeed(42).\n",
    "    setLabelCol(\"Cover_Type\").\n",
    "    setFeaturesCol(\"featureVector\").\n",
    "    setPredictionCol(\"prediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model = DecisionTreeClassificationModel (uid=dtc_64312fa273bd) of depth 5 with 63 nodes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassificationModel (uid=dtc_64312fa273bd) of depth 5 with 63 nodes"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model = classifier.fit(assembledTrainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=dtc_64312fa273bd) of depth 5 with 63 nodes\n",
      "  If (feature 0 <= 3052.5)\n",
      "   If (feature 0 <= 2563.5)\n",
      "    If (feature 10 <= 0.5)\n",
      "     If (feature 0 <= 2451.5)\n",
      "      If (feature 3 <= 15.0)\n",
      "       Predict: 4.0\n",
      "      Else (feature 3 > 15.0)\n",
      "       Predict: 3.0\n",
      "     Else (feature 0 > 2451.5)\n",
      "      If (feature 17 <= 0.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 17 > 0.5)\n",
      "       Predict: 3.0\n",
      "    Else (feature 10 > 0.5)\n",
      "     If (feature 22 <= 0.5)\n",
      "      If (feature 9 <= 4598.0)\n",
      "       Predict: 2.0\n",
      "      Else (feature 9 > 4598.0)\n",
      "       Predict: 2.0\n",
      "     Else (feature 22 > 0.5)\n",
      "      If (feature 9 <= 1102.0)\n",
      "       Predict: 2.0\n",
      "      Else (feature 9 > 1102.0)\n",
      "       Predict: 2.0\n",
      "   Else (feature 0 > 2563.5)\n",
      "    If (feature 0 <= 2942.5)\n",
      "     If (feature 15 <= 0.5)\n",
      "      If (feature 17 <= 0.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 17 > 0.5)\n",
      "       Predict: 3.0\n",
      "     Else (feature 15 > 0.5)\n",
      "      If (feature 9 <= 1357.5)\n",
      "       Predict: 3.0\n",
      "      Else (feature 9 > 1357.5)\n",
      "       Predict: 3.0\n",
      "    Else (feature 0 > 2942.5)\n",
      "     If (feature 3 <= 191.0)\n",
      "      If (feature 36 <= 0.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 36 > 0.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 3 > 191.0)\n",
      "      If (feature 7 <= 218.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 7 > 218.5)\n",
      "       Predict: 2.0\n",
      "  Else (feature 0 > 3052.5)\n",
      "   If (feature 0 <= 3311.5)\n",
      "    If (feature 7 <= 240.5)\n",
      "     If (feature 45 <= 0.5)\n",
      "      If (feature 42 <= 0.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 42 > 0.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 45 > 0.5)\n",
      "      If (feature 5 <= 4135.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 5 > 4135.5)\n",
      "       Predict: 1.0\n",
      "    Else (feature 7 > 240.5)\n",
      "     If (feature 3 <= 333.0)\n",
      "      If (feature 0 <= 3201.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 0 > 3201.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 3 > 333.0)\n",
      "      If (feature 0 <= 3201.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 0 > 3201.5)\n",
      "       Predict: 2.0\n",
      "   Else (feature 0 > 3311.5)\n",
      "    If (feature 12 <= 0.5)\n",
      "     If (feature 3 <= 274.5)\n",
      "      If (feature 6 <= 207.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 6 > 207.5)\n",
      "       Predict: 7.0\n",
      "     Else (feature 3 > 274.5)\n",
      "      If (feature 11 <= 0.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 11 > 0.5)\n",
      "       Predict: 1.0\n",
      "    Else (feature 12 > 0.5)\n",
      "     If (feature 45 <= 0.5)\n",
      "      If (feature 0 <= 3372.5)\n",
      "       Predict: 7.0\n",
      "      Else (feature 0 > 3372.5)\n",
      "       Predict: 7.0\n",
      "     Else (feature 45 > 0.5)\n",
      "      If (feature 5 <= 998.0)\n",
      "       Predict: 7.0\n",
      "      Else (feature 5 > 998.0)\n",
      "       Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(model.toDebugString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.778427540175678,Elevation)\n",
      "(0.040561444120305205,Horizontal_Distance_To_Hydrology)\n",
      "(0.03146363027227748,Hillshade_Noon)\n",
      "(0.03097607213882755,Wilderness_Area_0)\n",
      "(0.029083349083037755,Soil_Type_3)\n",
      "(0.027350706263280768,Soil_Type_31)\n",
      "(0.021927503190540414,Soil_Type_1)\n",
      "(0.011332055405466444,Wilderness_Area_2)\n",
      "(0.009588192084301072,Soil_Type_28)\n",
      "(0.006053830447010267,Soil_Type_22)\n",
      "(0.00571816142375842,Horizontal_Distance_To_Roadways)\n",
      "(0.003133165481742783,Wilderness_Area_1)\n",
      "(0.0022908420609322345,Hillshade_9am)\n",
      "(0.001805882250606783,Horizontal_Distance_To_Fire_Points)\n",
      "(2.8762560223494985E-4,Soil_Type_8)\n",
      "(0.0,Wilderness_Area_3)\n",
      "(0.0,Vertical_Distance_To_Hydrology)\n",
      "(0.0,Soil_Type_9)\n",
      "(0.0,Soil_Type_7)\n",
      "(0.0,Soil_Type_6)\n",
      "(0.0,Soil_Type_5)\n",
      "(0.0,Soil_Type_4)\n",
      "(0.0,Soil_Type_39)\n",
      "(0.0,Soil_Type_38)\n",
      "(0.0,Soil_Type_37)\n",
      "(0.0,Soil_Type_36)\n",
      "(0.0,Soil_Type_35)\n",
      "(0.0,Soil_Type_34)\n",
      "(0.0,Soil_Type_33)\n",
      "(0.0,Soil_Type_32)\n",
      "(0.0,Soil_Type_30)\n",
      "(0.0,Soil_Type_29)\n",
      "(0.0,Soil_Type_27)\n",
      "(0.0,Soil_Type_26)\n",
      "(0.0,Soil_Type_25)\n",
      "(0.0,Soil_Type_24)\n",
      "(0.0,Soil_Type_23)\n",
      "(0.0,Soil_Type_21)\n",
      "(0.0,Soil_Type_20)\n",
      "(0.0,Soil_Type_2)\n",
      "(0.0,Soil_Type_19)\n",
      "(0.0,Soil_Type_18)\n",
      "(0.0,Soil_Type_17)\n",
      "(0.0,Soil_Type_16)\n",
      "(0.0,Soil_Type_15)\n",
      "(0.0,Soil_Type_14)\n",
      "(0.0,Soil_Type_13)\n",
      "(0.0,Soil_Type_12)\n",
      "(0.0,Soil_Type_11)\n",
      "(0.0,Soil_Type_10)\n",
      "(0.0,Soil_Type_0)\n",
      "(0.0,Slope)\n",
      "(0.0,Hillshade_3pm)\n",
      "(0.0,Aspect)\n"
     ]
    }
   ],
   "source": [
    "model.featureImportances.toArray.zip(inputCols).sorted.reverse.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------------------------------------------------------------------------------------------------+\n",
      "|Cover_Type|prediction|probability                                                                                      |\n",
      "+----------+----------+-------------------------------------------------------------------------------------------------+\n",
      "|6.0       |3.0       |[0.0,0.0,0.033742225887365564,0.6317905370580352,0.04978868157921864,0.0,0.28467855547538057,0.0]|\n",
      "|6.0       |4.0       |[0.0,0.0,0.04389395914819644,0.2842242503259452,0.43415906127770537,0.0,0.23772272924815296,0.0] |\n",
      "|6.0       |3.0       |[0.0,0.0,0.033742225887365564,0.6317905370580352,0.04978868157921864,0.0,0.28467855547538057,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.033742225887365564,0.6317905370580352,0.04978868157921864,0.0,0.28467855547538057,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.033742225887365564,0.6317905370580352,0.04978868157921864,0.0,0.28467855547538057,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.033742225887365564,0.6317905370580352,0.04978868157921864,0.0,0.28467855547538057,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.033742225887365564,0.6317905370580352,0.04978868157921864,0.0,0.28467855547538057,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.033742225887365564,0.6317905370580352,0.04978868157921864,0.0,0.28467855547538057,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.033742225887365564,0.6317905370580352,0.04978868157921864,0.0,0.28467855547538057,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.033742225887365564,0.6317905370580352,0.04978868157921864,0.0,0.28467855547538057,0.0]|\n",
      "|3.0       |3.0       |[0.0,0.0,0.033742225887365564,0.6317905370580352,0.04978868157921864,0.0,0.28467855547538057,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.033742225887365564,0.6317905370580352,0.04978868157921864,0.0,0.28467855547538057,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.033742225887365564,0.6317905370580352,0.04978868157921864,0.0,0.28467855547538057,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.033742225887365564,0.6317905370580352,0.04978868157921864,0.0,0.28467855547538057,0.0]|\n",
      "|3.0       |3.0       |[0.0,0.0,0.033742225887365564,0.6317905370580352,0.04978868157921864,0.0,0.28467855547538057,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.033742225887365564,0.6317905370580352,0.04978868157921864,0.0,0.28467855547538057,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.033742225887365564,0.6317905370580352,0.04978868157921864,0.0,0.28467855547538057,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.033742225887365564,0.6317905370580352,0.04978868157921864,0.0,0.28467855547538057,0.0]|\n",
      "|3.0       |3.0       |[0.0,0.0,0.033742225887365564,0.6317905370580352,0.04978868157921864,0.0,0.28467855547538057,0.0]|\n",
      "|6.0       |3.0       |[0.0,0.0,0.033742225887365564,0.6317905370580352,0.04978868157921864,0.0,0.28467855547538057,0.0]|\n",
      "+----------+----------+-------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "predictions = [Elevation: int, Aspect: int ... 57 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Elevation: int, Aspect: int ... 57 more fields]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predictions = model.transform(assembledTrainData)\n",
    "predictions.select(\"Cover_Type\", \"prediction\", \"probability\").show(truncate = false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluator = mcEval_dc150c77fec1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "mcEval_dc150c77fec1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val evaluator = new MulticlassClassificationEvaluator().\n",
    "    setLabelCol(\"Cover_Type\").\n",
    "    setPredictionCol(\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6999359250227132"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.setMetricName(\"accuracy\").evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6823944459410305"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.setMetricName(\"f1\").evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.evaluation.MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictionRDD = MapPartitionsRDD[96] at rdd at <console>:43\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[96] at rdd at <console>:43"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predictionRDD = predictions.select(\"prediction\", \"Cover_Type\").as[(Double, Double)].rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "multiclassMetrics = org.apache.spark.mllib.evaluation.MulticlassMetrics@dc859ea\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.mllib.evaluation.MulticlassMetrics@dc859ea"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val multiclassMetrics = new MulticlassMetrics(predictionRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129136.0  55932.0   164.0    0.0    0.0  0.0  5379.0   \n",
       "50005.0   199738.0  4250.0   101.0  0.0  0.0  780.0    \n",
       "0.0       5843.0    25723.0  654.0  0.0  0.0  0.0      \n",
       "0.0       19.0      1449.0   999.0  0.0  0.0  0.0      \n",
       "43.0      7824.0    687.0    0.0    0.0  0.0  0.0      \n",
       "0.0       6106.0    8975.0   547.0  0.0  0.0  0.0      \n",
       "7887.0    182.0     54.0     0.0    0.0  0.0  10348.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclassMetrics.confusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "confusionMatrix = [Cover_Type: double, 1.0: bigint ... 4 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Cover_Type: double, 1.0: bigint ... 4 more fields]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val confusionMatrix = predictions.select(\"prediction\", \"Cover_Type\")\n",
    "    .groupBy(\"Cover_Type\").pivot(\"prediction\").count().na.fill(0).orderBy(\"Cover_Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+-----+---+-----+\n",
      "|Cover_Type|   1.0|   2.0|  3.0|4.0|  7.0|\n",
      "+----------+------+------+-----+---+-----+\n",
      "|       1.0|129136| 55932|  164|  0| 5379|\n",
      "|       2.0| 50005|199738| 4250|101|  780|\n",
      "|       3.0|     0|  5843|25723|654|    0|\n",
      "|       4.0|     0|    19| 1449|999|    0|\n",
      "|       5.0|    43|  7824|  687|  0|    0|\n",
      "|       6.0|     0|  6106| 8975|547|    0|\n",
      "|       7.0|  7887|   182|   54|  0|10348|\n",
      "+----------+------+------+-----+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusionMatrix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classProbabilities: (data: org.apache.spark.sql.DataFrame)Array[Double]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def classProbabilities(data: DataFrame): Array[Double] = {\n",
    "    val total = data.count()\n",
    "    data.groupBy(\"Cover_Type\").count().\n",
    "      orderBy(\"Cover_Type\").\n",
    "      select(\"count\").as[Double].\n",
    "      map(_ / total).\n",
    "      collect()\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainPriorProbabilities = Array(0.3645789700186487, 0.4874939033137283, 0.061626739348730454, 0.004718596088557357, 0.01636111509587338, 0.029891455075790177, 0.03532922105867164)\n",
       "testPriorProbabilities = Array(0.36484094385343807, 0.4885455514118274, 0.060735215769845495, 0.004812071424888721, 0.016137625242751818, 0.029886400742433875, 0.035042191554814646)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.37733732374892875"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainPriorProbabilities = classProbabilities(trainData)\n",
    "val testPriorProbabilities = classProbabilities(testData)\n",
    "trainPriorProbabilities.zip(testPriorProbabilities).map{\n",
    "    case(trainProb, cvProb) => trainProb * cvProb\n",
    "}.sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
